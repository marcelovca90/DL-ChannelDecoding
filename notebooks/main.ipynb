{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On Deep Learning-Based Channel Decoding\n",
    "\n",
    "If you want to cite this notebook, please use the following bibtext entry:\n",
    "\n",
    "    @article{nn-decoding,\n",
    "      title={On Deep Learning-Based Channel Decoding},\n",
    "      author={Tobias Gruber and\n",
    "              Sebastian Cammerer and\n",
    "              Jakob Hoydis and\n",
    "              Stephan ten Brink}\n",
    "      journal={CoRR}\n",
    "      year={2017}\n",
    "      url= {http://arxiv.org/abs/1701.07738}\n",
    "    }\n",
    "\n",
    "Running this example requires Keras installed with the Theano backend. For GPU support nvidia-docker is required. A Dockerfile is provided to employ this setup quickly.\n",
    "\n",
    "Our simulation setup was inspired by material from http://radioml.org.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Lambda\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8                       # number of information bits\n",
    "N = 16                      # code length\n",
    "train_SNR_Eb = 1            # training-Eb/No\n",
    "\n",
    "nb_epoch = 2**16            # number of learning epochs\n",
    "code = 'polar'              # type of code ('random' or 'polar')\n",
    "design = [128, 64, 32]      # each list entry defines the number of nodes in a layer\n",
    "batch_size = 256            # size of batches for calculation the gradient\n",
    "LLR = False                 # 'True' enables the log-likelihood-ratio layer\n",
    "optimizer = 'adam'           \n",
    "loss = 'mse'                # or 'binary_crossentropy'\n",
    "\n",
    "train_SNR_Es = train_SNR_Eb + 10*np.log10(k/N)\n",
    "train_sigma = np.sqrt(1/(2*10**(train_SNR_Es/10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modulateBPSK(x):\n",
    "    return -2*x +1;\n",
    "\n",
    "def addNoise(x, sigma):\n",
    "    w = K.random_normal(K.shape(x), mean=0.0, stddev=sigma)\n",
    "    return x + w\n",
    "\n",
    "def ber(y_true, y_pred):\n",
    "    return K.mean(K.not_equal(y_true, K.round(y_pred)))\n",
    "\n",
    "def return_output_shape(input_shape):  \n",
    "    return input_shape\n",
    "\n",
    "def compose_model(layers):\n",
    "    model = Sequential()\n",
    "    for layer in layers:\n",
    "        model.add(layer)\n",
    "    return model\n",
    "\n",
    "def log_likelihood_ratio(x, sigma):\n",
    "    return 2*x/np.float32(sigma**2)\n",
    "\n",
    "def errors(y_true, y_pred):\n",
    "    return K.sum(K.not_equal(y_true, K.round(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define modulator\n",
    "modulator_layers = [Lambda(modulateBPSK, \n",
    "                          input_shape=(N,), output_shape=return_output_shape, name=\"modulator\")]\n",
    "modulator = compose_model(modulator_layers)\n",
    "modulator.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# Define noise\n",
    "noise_layers = [Lambda(addNoise, arguments={'sigma':train_sigma}, \n",
    "                       input_shape=(N,), output_shape=return_output_shape, name=\"noise\")]\n",
    "noise = compose_model(noise_layers)\n",
    "noise.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# Define LLR\n",
    "llr_layers = [Lambda(log_likelihood_ratio, arguments={'sigma':train_sigma}, \n",
    "                     input_shape=(N,), output_shape=return_output_shape, name=\"LLR\")]\n",
    "llr = compose_model(llr_layers)\n",
    "llr.compile(optimizer=optimizer, loss=loss)\n",
    "\n",
    "# Define decoder \n",
    "decoder_layers = [Dense(design[0], activation='relu', input_shape=(N,))]\n",
    "for i in range(1,len(design)):\n",
    "    decoder_layers.append(Dense(design[i], activation='relu'))\n",
    "decoder_layers.append(Dense(k, activation='sigmoid'))\n",
    "decoder = compose_model(decoder_layers)\n",
    "decoder.compile(optimizer=optimizer, loss=loss, metrics=[errors])\n",
    "\n",
    "# Define model\n",
    "if LLR:\n",
    "    model_layers = modulator_layers + noise_layers + llr_layers + decoder_layers\n",
    "else:\n",
    "    model_layers = modulator_layers + noise_layers + decoder_layers\n",
    "model = compose_model(model_layers)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=[ber])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def half_adder(a,b):\n",
    "    s = a ^ b\n",
    "    c = a & b\n",
    "    return s,c\n",
    "\n",
    "def full_adder(a,b,c):\n",
    "    s = (a ^ b) ^ c\n",
    "    c = (a & b) | (c & (a ^ b))\n",
    "    return s,c\n",
    "\n",
    "def add_bool(a,b):\n",
    "    if len(a) != len(b):\n",
    "        raise ValueError('arrays with different length')\n",
    "    k = len(a)\n",
    "    s = np.zeros(k,dtype=bool)\n",
    "    c = False\n",
    "    for i in reversed(range(0,k)):\n",
    "        s[i], c = full_adder(a[i],b[i],c)    \n",
    "    if c:\n",
    "        warnings.warn(\"Addition overflow!\")\n",
    "    return s\n",
    "\n",
    "def inc_bool(a):\n",
    "    k = len(a)\n",
    "    increment = np.hstack((np.zeros(k-1,dtype=bool), np.ones(1,dtype=bool)))\n",
    "    a = add_bool(a,increment)\n",
    "    return a\n",
    "\n",
    "def bitrevorder(x):\n",
    "    m = np.amax(x)\n",
    "    n = np.ceil(np.log2(m)).astype(int)\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = int('{:0{n}b}'.format(x[i],n=n)[::-1],2)  \n",
    "    return x\n",
    "\n",
    "def int2bin(x,N):\n",
    "    if isinstance(x, list) or isinstance(x, np.ndarray):\n",
    "        binary = np.zeros((len(x),N),dtype='bool')\n",
    "        for i in range(0,len(x)):\n",
    "            binary[i] = np.array([int(j) for j in bin(x[i])[2:].zfill(N)])\n",
    "    else:\n",
    "        binary = np.array([int(j) for j in bin(x)[2:].zfill(N)],dtype=bool)\n",
    "    \n",
    "    return binary\n",
    "\n",
    "def bin2int(b):\n",
    "    if isinstance(b[0], list):\n",
    "        integer = np.zeros((len(b),),dtype=int)\n",
    "        for i in range(0,len(b)):\n",
    "            out = 0\n",
    "            for bit in b[i]:\n",
    "                out = (out << 1) | bit\n",
    "            integer[i] = out\n",
    "    elif isinstance(b, np.ndarray):\n",
    "        if len(b.shape) == 1:\n",
    "            out = 0\n",
    "            for bit in b:\n",
    "                out = (out << 1) | bit\n",
    "            integer = out     \n",
    "        else:\n",
    "            integer = np.zeros((b.shape[0],),dtype=int)\n",
    "            for i in range(0,b.shape[0]):\n",
    "                out = 0\n",
    "                for bit in b[i]:\n",
    "                    out = (out << 1) | bit\n",
    "                integer[i] = out\n",
    "        \n",
    "    return integer\n",
    "\n",
    "def polar_design_awgn(N, k, design_snr_dB):  \n",
    "        \n",
    "    S = 10**(design_snr_dB/10)\n",
    "    z0 = np.zeros(N)\n",
    "\n",
    "    z0[0] = np.exp(-S)\n",
    "    for j in range(1,int(np.log2(N))+1):\n",
    "        u = 2**j\n",
    "        for t in range(0,int(u/2)):\n",
    "            T = z0[t]\n",
    "            z0[t] = 2*T - T**2     # upper channel\n",
    "            z0[int(u/2)+t] = T**2  # lower channel\n",
    "        \n",
    "    # sort into increasing order\n",
    "    idx = np.argsort(z0)\n",
    "        \n",
    "    # select k best channels\n",
    "    idx = np.sort(bitrevorder(idx[0:k]))\n",
    "    \n",
    "    A = np.zeros(N, dtype=bool)\n",
    "    A[idx] = True\n",
    "        \n",
    "    return A\n",
    "\n",
    "def polar_transform_iter(u):\n",
    "\n",
    "    N = len(u)\n",
    "    n = 1\n",
    "    x = np.copy(u)\n",
    "    stages = np.log2(N).astype(int)\n",
    "    for s in range(0,stages):\n",
    "        i = 0\n",
    "        while i < N:\n",
    "            for j in range(0,n):\n",
    "                idx = i+j\n",
    "                x[idx] = x[idx] ^ x[idx+n]\n",
    "            i=i+2*n\n",
    "        n=2*n\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create all possible information words\n",
    "d = np.zeros((2**k,k),dtype=bool)\n",
    "for i in range(1,2**k):\n",
    "    d[i]= inc_bool(d[i-1])\n",
    "\n",
    "# Create sets of all possible codewords (codebook)\n",
    "if code == 'polar':   \n",
    "    \n",
    "    A = polar_design_awgn(N, k, design_snr_dB=0)  # logical vector indicating the nonfrozen bit locations \n",
    "    x = np.zeros((2**k, N),dtype=bool)\n",
    "    u = np.zeros((2**k, N),dtype=bool)\n",
    "    u[:,A] = d\n",
    "\n",
    "    for i in range(0,2**k):\n",
    "        x[i] = polar_transform_iter(u[i])\n",
    "\n",
    "elif code == 'random':\n",
    "    \n",
    "    np.random.seed(4267)   # for a 16bit Random Code (r=0.5) with Hamming distance >= 2\n",
    "    x = np.random.randint(0,2,size=(2**k,N), dtype=bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "history = model.fit(x, d, batch_size=batch_size, nb_epoch=nb_epoch, verbose=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = 1000  \n",
    "num_words = 100000      # multiple of test_batch\n",
    "\n",
    "SNR_dB_start_Eb = 0\n",
    "SNR_dB_stop_Eb = 5\n",
    "SNR_points = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SNR_dB_start_Es = SNR_dB_start_Eb + 10*np.log10(k/N)\n",
    "SNR_dB_stop_Es = SNR_dB_stop_Eb + 10*np.log10(k/N)\n",
    "\n",
    "sigma_start = np.sqrt(1/(2*10**(SNR_dB_start_Es/10)))\n",
    "sigma_stop = np.sqrt(1/(2*10**(SNR_dB_stop_Es/10)))\n",
    "\n",
    "sigmas = np.linspace(sigma_start, sigma_stop, SNR_points)\n",
    "\n",
    "nb_errors = np.zeros(len(sigmas),dtype=int)\n",
    "nb_bits = np.zeros(len(sigmas),dtype=int)\n",
    "\n",
    "for i in range(0,len(sigmas)):\n",
    "\n",
    "    for ii in range(0,np.round(num_words/test_batch).astype(int)):\n",
    "        \n",
    "        # Source\n",
    "        np.random.seed(0)\n",
    "        d_test = np.random.randint(0,2,size=(test_batch,k)) \n",
    "\n",
    "        # Encoder\n",
    "        if code == 'polar':\n",
    "            x_test = np.zeros((test_batch, N),dtype=bool)\n",
    "            u_test = np.zeros((test_batch, N),dtype=bool)\n",
    "            u_test[:,A] = d_test\n",
    "\n",
    "            for iii in range(0,test_batch):\n",
    "                x_test[iii] = polar_transform_iter(u_test[iii])\n",
    "\n",
    "        elif code == 'random':\n",
    "            x_test = np.zeros((test_batch, N),dtype=bool)\n",
    "            for iii in range(0,test_batch):\n",
    "                x_test[iii] = x[bin2int(d_test[iii])]\n",
    "\n",
    "        # Modulator (BPSK)\n",
    "        s_test = -2*x_test + 1\n",
    "\n",
    "        # Channel (AWGN)\n",
    "        y_test = s_test + sigmas[i]*np.random.standard_normal(s_test.shape)\n",
    "\n",
    "        if LLR:\n",
    "            y_test = 2*y_test/(sigmas[i]**2)\n",
    "\n",
    "        # Decoder\n",
    "        nb_errors[i] += decoder.evaluate(y_test, d_test, batch_size=test_batch, verbose=0)[1]\n",
    "        nb_bits[i] += d_test.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_map = np.loadtxt('map/{}/results_{}_map_{}_{}.txt'.format(code,code,N,k), delimiter=', ')\n",
    "sigmas_map = result_map[:,0]\n",
    "nb_bits_map = result_map[:,1]\n",
    "nb_errors_map = result_map[:,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot Bit-Error-Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = []\n",
    "\n",
    "plt.plot(10*np.log10(1/(2*sigmas**2)) - 10*np.log10(k/N), nb_errors/nb_bits)\n",
    "legend.append('NN') \n",
    "\n",
    "plt.plot(10*np.log10(1/(2*sigmas_map**2)) - 10*np.log10(k/N), nb_errors_map/nb_bits_map)\n",
    "legend.append('MAP') \n",
    "\n",
    "plt.legend(legend, loc=3)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('$E_b/N_0$')\n",
    "plt.ylabel('BER')    \n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
